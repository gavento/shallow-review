# Prompts for draft document processing: extracting structured metadata from research agendas

extract_agenda_attributes:
  user: |
    You are extracting structured metadata from a research agenda in a shallow review document.
    
    You will receive:
    1. A DocumentItem structure (JSON) with id, name, header_level, parent_id, item_type already filled
    2. The markdown content for this item in <content></content> XML tags
    
    Your task: Return the SAME DocumentItem structure with agenda_attributes populated and parsing_issues added. Preserve id, name, header_level, parent_id, and item_type fields exactly.
    
    **Input DocumentItem:**
    ```json
    {{ item_json }}
    ```
    
    **Markdown content to extract from:**
    <content>
    {{ content }}
    </content>
    
    Extract the following information from the content:
    
    **Standard Attributes** (extract if present, look for these bold headers):
    - who_edits: From "**Who edits (internal):**" - Editor name, possibly with status emoji
    - one_sentence_summary: From "**One-sentence summary:**" - Brief description
    - theory_of_change: From "**Theory of change:**" - How this work contributes to safety
    - see_also: From "**See also:**" - Related agenda IDs (list of strings like "a:id1", "a:id2", "sec:id1"). Use the agenda list below to resolve plain text references to IDs.
    - orthodox_problems: From "**Orthodox problems:**" - List of orthodox problem IDs (see table below)
    - target_case: From "**Target case:**" - Target case ID (see table below)
    - broad_approach: From "**Broad approach:**" - Broad approach ID (see table below)
    - some_names: From "**Some names:**" - Key researchers (list)
    - estimated_ftes: From "**Estimated FTEs:**" - Workforce estimate
    - critiques: From "**Critiques:**" - Critiques as markdown text (links, descriptions, etc.)
    - funded_by: From "**Funded by:**" - Funders (optional)
    - funding_in_2025: From "**Funding in 2025:**" - Dollar amounts (optional)
    - organization_structure: From "**Host org structure:**" or "**Structure:**" - Organization type (e.g., "public benefit corp", "for-profit", "research laboratory subsidiary of a for-profit")
    - teams: From "**Teams:**" - Teams/divisions description in markdown (e.g. for labs)
    - public_alignment_agenda: From "**Public alignment agenda:**" and/or "**Public plan:**" - Merge both if present (e.g. for labs)
    - framework: From "**Framework:**" - Framework link/description in markdown (e.g. for labs)
    
    **Available Agendas and Sections** (use these IDs in see_also):
    {% for item in agenda_list %}
    - {{ item.id }}: {{ item.name }}
    {% endfor %}
    
    **Orthodox Problems** (use IDs from this table):
    {% for problem_id, problem_info in orthodox_problems.items() %}
    - {{ problem_id }}: {{ problem_info.name }}
    {% endfor %}
    
    **Target Cases** (use IDs from this table):
    {% for case_id, case_info in target_cases.items() %}
    - {{ case_id }}: {{ case_info.name }}
    {% endfor %}
    
    **Broad Approaches** (use IDs from this table):
    {% for approach_id, approach_info in broad_approaches.items() %}
    - {{ approach_id }}: {{ approach_info.name }}
    {% endfor %}
    
    **Outputs** (extract from "**Outputs in 2025:**" or "**Outputs:**" section if present):
    - Extract all output items (papers, blog posts, etc.) as a flat list
    - For items with URLs: Extract the URL and preserve the original markdown
    - For items without URLs: Set url=null and preserve the original markdown in original_md
    - For subsection headers (e.g., "### Interpretability at pretrain-time"): Create OutputSectionHeader items with name, header_level, and original_md
    - Ignore the header depth - just preserve the structure and order
    - Leave title, authors, date, venue, kind, summary, key_result as null (they will be enriched from database later)
    
    **Other Attributes**: Any attributes with **Attribute Name:** format that don't match the standard ones above.
    
    **Parsing Issues**: Detect and report any issues with the content or parsing:
    - Source document issues: missing headers, wrong sec:/a: markers, formatting problems
    - Content issues: empty/minimal content, mismatched titles, wrong company/org info
    - Parsing issues: confusion about structure, ambiguous attributions, etc.
    If everything looks correct and complete, return an empty list.
    
    **EXAMPLES:**
    
    Example 1 - Lab/Organization (a:openai):
    
    Input DocumentItem:
    ```json
    {
      "id": "a:openai",
      "name": "OpenAI Safety",
      "header_level": 2,
      "parent_id": "sec:big_labs",
      "content": null,
      "item_type": "agenda",
      "agenda_attributes": null,
      "parsing_issues": []
    }
    ```
    
    Content:
    <content>
    **See also:** iterative alignment, safeguards, personas.
    **Host org structure**: public benefit corp
    **Teams**: Alignment, Safety Systems (Interpretability, Safety Oversight, Pretraining Safety)
    **Public alignment agenda:** [None](https://openai.com/safety). Barak [offers](https://lesswrong.com) personal views.
    **Public plan**: [Preparedness Framework](https://cdn.openai.com/pdf/preparedness-framework.pdf)
    **Critiques:** [Stein-Perlman](https://ailabwatch.org/companies/openai)
    **Some names:** Johannes Heidecke, Boaz Barak
    **Funded by:** Microsoft, AWS, Oracle
    **Outputs in 2025:**
    * Their System Cards contain safety work.
    * [https://alignment.openai.com/](https://alignment.openai.com/)
    </content>
    
    Output DocumentItem (only non-default values shown):
    ```json
    {
      "id": "a:openai",
      "name": "OpenAI Safety",
      "header_level": 2,
      "parent_id": "sec:big_labs",
      "content": null,
      "item_type": "agenda",
      "agenda_attributes": {
        "see_also": ["sec:iterative_alignment", "a:anthropic_safeguards", "a:psych_personas"],
        "some_names": ["Johannes Heidecke", "Boaz Barak"],
        "critiques": "[Stein-Perlman](https://ailabwatch.org/companies/openai)",
        "funded_by": "Microsoft, AWS, Oracle",
        "organization_structure": "public benefit corp",
        "teams": "Alignment, Safety Systems (Interpretability, Safety Oversight, Pretraining Safety)",
        "public_alignment_agenda": "[None](https://openai.com/safety). Barak [offers](https://lesswrong.com) personal views. **Public plan**: [Preparedness Framework](https://cdn.openai.com/pdf/preparedness-framework.pdf)",
        "outputs": [
          {"original_md": "* Their System Cards contain safety work."},
          {"url": "https://alignment.openai.com/", "original_md": "* [https://alignment.openai.com/](https://alignment.openai.com/)"}
        ]
      },
      "parsing_issues": []
    }
    ```
    
    Example 2 - Research Agenda (sec:iterative_alignment):
    
    Input DocumentItem:
    ```json
    {
      "id": "a:iterative_alignment",
      "name": "Iterative alignment",
      "header_level": 2,
      "parent_id": null,
      "content": null,
      "item_type": "section",
      "agenda_attributes": null,
      "parsing_issues": []
    }
    ```
    
    Content:
    <content>
    
    **Who edits (internal):** Stag✅
    **One-sentence summary:** nudging base models by optimising their output.
    **Theory of change:** LLMs don't seem very dangerous and might scale to AGI, assume alignment is a superficial feature.
    **See also:** character training
    **Orthodox problems:** this agenda implicitly questions this framing.
    **Target case:** optimistic-case
    **Broad approach:** Engineering
    **Some names:** post-training teams at most labs.
    **Estimated FTEs:** 1200+
    **Funded by:** most of the industry
    **Outputs:** Subdivided as follows:
    
    ### Iterative alignment at pretrain-time
    * [**Towards Cognitively-Faithful Models**](https://arxiv.org/abs/2509.04445)
    
    ### Iterative alignment at post-train-time
    * [https://arxiv.org/abs/2501.08617](https://arxiv.org/abs/2501.08617), Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L. Griffiths, Jaime Fernández Fisac, 2025 
    * https://arxiv.org/abs/2503.04569
    </content>
    
    Output DocumentItem (only non-default values shown):
    ```json
    {
      "id": "sec:iterative_alignment",
      "name": "Iterative alignment",
      "header_level": 2,
      "parent_id": null,
      "content": null,
      "item_type": "section",
      "agenda_attributes": {
        "who_edits": "Stag✅",
        "one_sentence_summary": "nudging base models by optimising their output.",
        "theory_of_change": "LLMs don't seem very dangerous and might scale to AGI, assume alignment is a superficial feature.",
        "see_also": ["a:psych_personas"],
        "target_case": "average_case",
        "broad_approach": "engineering",
        "some_names": ["post-training teams at most labs"],
        "estimated_ftes": "1200+",
        "funded_by": "most of the industry",
        "outputs": [
          {
            "name": "Iterative alignment at pretrain-time",
            "header_level": 3,
            "original_md": "### Iterative alignment at pretrain-time"
          },
          {
            "url": "https://arxiv.org/abs/2509.04445",
            "original_md": "* [**Towards Cognitively-Faithful Models**](https://arxiv.org/abs/2509.04445)"
          },
          {
            "name": "Iterative alignment at post-train-time",
            "header_level": 3,
            "original_md": "### Iterative alignment at post-train-time"
          },
          {
            "url": "https://arxiv.org/abs/2501.08617",
            "original_md": "* [**RLHS: Mitigating Misalignment**](https://arxiv.org/abs/2501.08617), Kaiqu Liang, Haimin Hu, Ryan Liu, Thomas L. Griffiths, Jaime Fernández Fisac, 2025"
          },
          {
            "url": "https://arxiv.org/abs/2503.04569",
            "original_md": "* https://arxiv.org/abs/2503.04569"
          }
        ]
      },
      "parsing_issues": [
        "Orthodox problems field says 'this agenda implicitly questions this framing' - unclear which problems this relates to",
        "Target case field says 'optimistic-case' - closest match is 'average_case'",
        "Funded by field says 'most of the industry' - unclear which industry this relates to"
      ]
    }
    ```
    
    Note in examples:
    - **Omit default values**: Fields with defaults (null, [], {}) can be omitted from output for brevity. The examples above show only non-default values.
    - Extract text EXACTLY as written, preserving markdown formatting
    - For "see_also": resolve external links to agenda IDs when possible (e.g., "character training" with link to [a:psych_personas] becomes "a:psych_personas")
    - For "target_case": map "optimistic-case" to "optimistic_case" (closest match)
    - For organization/labs: focus on teams, funders, structure, public plans
    - For research agendas: focus on theory of change, orthodox problems, target case, broad approach
    - Merge "Public alignment agenda" and "Public plan" fields into single "public_alignment_agenda"
    - For "outputs": Extract all items from "**Outputs in 2025:**" or "**Outputs:**" section
      - URLs go in "url" field, preserve full markdown in "original_md"
      - Items without URLs: omit "url" field (defaults to null), include "original_md"
      - Subsection headers: OutputSectionHeader with "name", "header_level", "original_md" (omit description if not present)
      - Preserve order and structure, leave database fields (title, authors, etc.) as null (can be omitted)
    
    IMPORTANT: 
    - Return valid JSON only. Do not use backslash escapes except for standard JSON escapes (\\n, \\t, \\", \\\\).
    - Preserve markdown formatting exactly as written in the source.
    - **Omit fields with default values** (null, [], {}) for brevity - they will be filled in automatically.
    
    **JSON Schema for Output:**
    
    DocumentItem (must match input structure exactly):
    - id: string (REQUIRED, must match input)
    - name: string (REQUIRED, must match input)
    - header_level: integer (REQUIRED, must match input)
    - parent_id: string | null (REQUIRED, must match input)
    - agenda_attributes: AgendaAttributes | null (populate this)
    - content: string | null (REQUIRED, only the relevant content that is not represented in agenda_attributes, e.g. quotes, non-internal meta or epistemic remarks etc.; stand-alone markdown text)
    - item_type: "section" | "agenda" (REQUIRED, must match input)
    - parsing_issues: string[] (defaults to [])
    
    AgendaAttributes (omit fields with default values):
    - who_edits: string | null
    - one_sentence_summary: string | null
    - theory_of_change: string | null
    - see_also: string[] (defaults to [])
    - orthodox_problems: string[] (defaults to [])
    - target_case: string | null
    - broad_approach: string | null
    - some_names: string[] (defaults to [])
    - estimated_ftes: string | null
    - critiques: string | null
    - funded_by: string | null
    - funding_in_2025: string | null
    - organization_structure: string | null
    - teams: string | null
    - public_alignment_agenda: string | null
    - framework: string | null
    - outputs: (Paper | OutputSectionHeader)[] (defaults to [])
    - other_attributes: object (defaults to {})
    
    Paper:
    - url: string | null
    - original_md: string (REQUIRED)
    - title, authors, author_organizations, date, published_year, venue, kind, summary, key_result: (omit, defaults to null/[])
    
    OutputSectionHeader:
    - name: string (REQUIRED)
    - header_level: integer (REQUIRED)
    - description: string | null
    - original_md: string (REQUIRED)
