# Prompts for draft document processing: extracting structured metadata from research agendas

extract_agenda_attributes:
  user: |
    You are extracting structured metadata given a single research agenda. The given agenda is part of the "Shallow review of technical AI safety" document.

    You will receive:
    1. A DocumentItem structure (JSON) in <document_item></document_item> with id, name, header_level, parent_id, item_type already filled
    2. The markdown content for this item in <content></content> XML tags

    Your task: Return the SAME DocumentItem structure with agenda_attributes populated and parsing_issues added. Preserve id, name, header_level, parent_id, and item_type fields exactly.

    # Input DocumentItem

    <document_item>
    {{ item_json }}
    </document_item>

    # Markdown content to extract from

    <content>
    {{ content }}
    </content>

    # Extract the following information from the content

    ## Standard Attributes

    Extract if present, look for these line prefixes, usually bold:

    - who_edits: From "**Who edits (internal):**" - Editor name, possibly with status emoji
    - one_sentence_summary: From "**One-sentence summary:**" - Brief description as one markdown text block (optional)
    - theory_of_change: From "**Theory of change:**" - How this work contributes to safety as one markdown text block (optional)
    - see_also: From "**See also:**" - Related agenda IDs (list of strings like "a:id1", "a:id2", "sec:id1"), mixed with markdown text (external see also links and text that does not match any of the agendas). Use the agenda list below to resolve plain text references to IDs.
    - orthodox_problems: From "**Orthodox problems:**" - List of orthodox problem IDs (see table below)
    - target_case_id: From "**Target case:**" - Target case ID (see table below). If present, this must be one of: "average_case", "pessimistic_case", or "worst_case". "optimistic" should be mapped to "average_case" (do not warn about this). In case of "mixed", "varies" etc, leave null.
    - target_case_text: From "**Target case:**" - Target case texttual representation. This should be one of "average" (also use for "optimistic"), "pessimistic", "worst-case". In case of "mixed", "varies" etc, transform to small-caps plain-text short version (e.g. "mixed") and warn about this. May be null if target case is not present.
    - broad_approach_id: From "**Broad approach:**" - Broad approach ID (see table below). If present, this must be one of: "engineering", "behaviorist_science" (also for "behaviorist" or "behavioral"), or "cognitivist_science" (also for "cognitivist" or "cognitive"). In case of "mixed", "varies", a longer comment, etc, leave this field null.
    - broad_approach_text: From "**Broad approach:**" - Broad approach text (if present, this must be one of: "engineering", "behaviorist science", or "cognitivist science". In case of "mixed", "varies", multiple approaches, a longer comment, etc, transform the text to a small-caps plain-text short version (e.g. "mixed") and warn about this. Separate multiple approaches with "/" with space between them. May be null if broad approach info is not present.
    - some_names: From "**Some names:**" - Key researchers (list)
    - estimated_ftes: From "**Estimated FTEs:**" - Workforce estimate
    - critiques: From "**Critiques:**" - Critiques as one markdown text block (links, descriptions, etc., optional)
    - funded_by: From "**Funded by:**" - Funders as one markdown text block (optional)

    ## Other Attributes

    Any attributes with line prefix that don't match the standard ones above but clearly indicate an attribute:

    - other_attributes: a dictionary of other attributes that don't fit into the standard attributes. The keys may be:
      - "Structure" (also from "Host org structure") (e.g., "public benefit corp", "for-profit", "research laboratory subsidiary of a for-profit")
      - "Teams"
      - "Public alignment agenda" (sometimes also from "Public plan")
      - "Framework": Framework link/description in markdown (sometimes also from "Public plan", depending on context)
    - Store the keys as plain text (remove bolding, ":", etc.)

    # Available Agendas and Sections

    Use these IDs in see_also. Note the match is semantic and can be approximate.
    {% for item in agenda_list %}
    - {{ item.name }}: {{ item.id }}
    {% endfor %}

    # Orthodox Problems

    Use IDs from this list. Note the match is semantic and can be approximate. In some cases, the ortodox problem may not match any of the listed problems - in that case, include it as "Other: <original_text>".
    {% for problem_id, problem_info in orthodox_problems.items() %}
    - {{ problem_info.name }}: {{ problem_id }}
    {% endfor %}

    # Target Cases

    Use IDs from this list. Note the match is semantic and can be approximate.
    {% for case_id, case_info in target_cases.items() %}
    - {{ case_info.name }}: {{ case_id }}
    {% endfor %}

    # Broad Approaches

    Use IDs from this list. Note the match is semantic and can be approximate.
    {% for approach_id, approach_info in broad_approaches.items() %}
    - {{ approach_id }}: {{ approach_info.name }}
    {% endfor %}

    # Outputs

    Extract from "**Outputs in 2025:**" or "**Outputs:**" attributes if present. Note that this part is always last in the content, and it may contain subsections.
    Extract as a list of links (to papers and other outputs), non-link references (eg. "Countless examples on X") and output subsection headers, preserving the order.
    - For links with URLs and plain-text URLs: Extract the URL as `{"link_url": URL, "link_text": TEXT_OR_NULL, "original_md": ORIGINAL_MD}`
    - For text items without URLs: Extract as `{"link_url": null, "link_text": CLEANED_TEXT, "original_md": ORIGINAL_MD}`
    - For subsection headers (e.g., "#### Experimental results"): Extract as `{"section_name": "Experimental results", "header_level": 4, "original_md": ORIGINAL_MD}`
    - In the output JSON, leave title, authors, date, year etc. absent (they will be enriched from database later)

    # Parsing Issues

    Detect and report any issues with the content or parsing:
    - Source document issues: missing headers, wrong sec:/a: markers, serious formatting problems, parsing ambiguity, etc.
    - Content issues: empty/minimal content, mismatched titles, clearly wrong company/org info, etc.
    - Parsing issues: confusion about structure, ambiguous attributions, etc.
    - If a field is empty or just "None", "Unknown", "?", "N/A" etc., leave it null. Do not mention this as a parsing issue.
    
    If everything looks correct and complete, return an empty list.

    # General instructions

    - If a value is specified as "", "None", "Unknown", "?", "N/A" etc., treat the field as absent.
    - Do not output null values for fields that are absent (incl. above) or empty - leave the field undefined.
    - Fix mismatched markdown formatting in the content. Tend to remove formatting rather than add item.
    - Remove trailing periods from text items, except for one-sentence summaries, theory of change, and any markdown field that already consists of sentences. Plain lists should never end in a period.
    - Ignore minor formatting issues like extra spaces, trailing spaces, etc. Similarly, some of the attribute names may be not bolded, slanted, etc. Remove spurious formatting from attribute values, e.g. when the *entire* value is in italics or bold, remove the italics or bold formatting.
    - Produce valid JSON. In particular, make sure to properly escape double quotes and backslashes in the JSON output.

    # EXAMPLES

    ## Example 1: Lab/Organization

    Example 1 Input JSON:
    <example1_document_item>
    {
      "id": "a:openai",
      "name": "OpenAI Safety",
      "header_level": 2,
      "parent_id": "sec:big_labs",
      "content": null,
      "item_type": "agenda",
      "agenda_attributes": null,
      "parsing_issues": []
    }
    </example1_document_item>

    Example 1 Content:
    <example1_content>
    ## OpenAI Safety \[a:openai\]

    **See also:** iterative alignment, safeguards, personas.

    **Host org structure**: public benefit corp

    **Teams**: Alignment, Safety Systems (Interpretability, "Safety" Oversight, Pretraining Safety, Robustness, Safety Research, Trustworthy AI, new Misalignment Research team [coming](https://archive.is/eDB1D)), Preparedness, Model Policy, Safety and Security Committee, Safety Advisory Group. The [Persona Features](https://www.arxiv.org/pdf/2506.19823) paper had a distinct author list. No named successor to Superalignment.

    **Public alignment agenda:** [None](https://openai.com/safety/how-we-think-about-safety-alignment/). Barak [offers](https://www.lesswrong.com/posts/3jnziqCF3vA2NXAKp/six-thoughts-on-ai-safety) personal [views](https://windowsontheory.org/2025/06/24/machines-of-faithful-obedience/).

    **Public plan**: [Preparedness Framework](https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf)

    **Critiques:** [Stein-Perlman](https://ailabwatch.org/companies/openai), [defense](https://www.wired.com/story/openai-anduril-defense/). It’s [difficult](https://conversationswithtyler.com/episodes/sam-altman-2/) to model OpenAI as a single agent: “*ALTMAN: I very rarely get to have anybody work on anything. One thing about researchers is they’re going to work on what they’re going to work on, and that’s that.”*

    **Some names:** Johannes Heidecke, Boaz Barak.

    **Funded by:** Microsoft, [AWS](https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure), Oracle, NVIDIA, SoftBank, G42, AMD, Dragoneer, Coatue, Thrive, Altimeter, MGX, Blackstone, TPG, T. Rowe Price, Andreessen Horowitz, D1 Capital Partners, Fidelity Investments, Founders Fund, Sequoia…

    **Outputs in 2025:**

    * Their 60-page System Cards now contain a large amount of their public safety work.
    * [https://alignment.openai.com/](https://alignment.openai.com/)
    * [**Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation**](https://arxiv.org/abs/2503.11926)
    * [**Persona Features Control Emergent Misalignment**](https://arxiv.org/abs/2506.19823)
    </example1_content>

    Example 1 Output JSON:
    ```json
    {
      "id": "a:openai",
      "name": "OpenAI Safety",
      "header_level": 2,
      "parent_id": "sec:big_labs",
      "content": null,
      "item_type": "agenda",
      "agenda_attributes": {
        "see_also": ["sec:iterative_alignment", "a:anthropic_safeguards", "a:psych_personas"],
        "some_names": ["Johannes Heidecke", "Boaz Barak"],
        "critiques": "[Stein-Perlman](https://ailabwatch.org/companies/openai), [defense](https://www.wired.com/story/openai-anduril-defense/). It’s [difficult](https://conversationswithtyler.com/episodes/sam-altman-2/) to model OpenAI as a single agent: *“ALTMAN: I very rarely get to have anybody work on anything. One thing about researchers is they’re going to work on what they’re going to work on, and that’s that.”*",
        "funded_by": "Microsoft, [AWS](https://www.aboutamazon.com/news/aws/aws-open-ai-workloads-compute-infrastructure), Oracle, NVIDIA, SoftBank, G42, AMD, Dragoneer, Coatue, Thrive, Altimeter, MGX, Blackstone, TPG, T. Rowe Price, Andreessen Horowitz, D1 Capital Partners, Fidelity Investments, Founders Fund, Sequoia…",
        "other_attributes": {
          "Structure": "public benefit corp",
          "Teams": "Alignment, Safety Systems (Interpretability, \"Safety\" Oversight, Pretraining Safety, Robustness, Safety Research, Trustworthy AI, new Misalignment Research team [coming](https://archive.is/eDB1D)), Preparedness, Model Policy, Safety and Security Committee, Safety Advisory Group. The [Persona Features](https://www.arxiv.org/pdf/2506.19823) paper had a distinct author list. No named successor to Superalignment.",
          "Public alignment agenda": "[None](https://openai.com/safety/how-we-think-about-safety-alignment/). Barak [offers](https://www.lesswrong.com/posts/3jnziqCF3vA2NXAKp/six-thoughts-on-ai-safety) personal [views](https://windowsontheory.org/2025/06/24/machines-of-faithful-obedience/).",
          "Framework": "[Preparedness Framework](https://cdn.openai.com/pdf/18a02b5d-6b67-4cec-ab64-68cdfbddebcd/preparedness-framework-v2.pdf)"
        },
        "outputs": [
          {"link_url": null, "link_text": "Their 60-page System Cards now contain a large amount of their public safety work.", "original_md": "* Their 60-page System Cards now contain a large amount of their public safety work."},
          {"link_url": "https://alignment.openai.com/", "link_text": "https://alignment.openai.com/", "original_md": "* [https://alignment.openai.com/](https://alignment.openai.com/)"},
          {"link_url": "https://arxiv.org/abs/2503.11926", "link_text": "Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation", "original_md": "* [**Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation**](https://arxiv.org/abs/2503.11926)"},
          {"link_url": "https://arxiv.org/abs/2506.19823", "link_text": "Persona Features Control Emergent Misalignment", "original_md": "* [**Persona Features Control Emergent Misalignment**](https://arxiv.org/abs/2506.19823)"}
        ]
      },
      "parsing_issues": []
    }
    ```

    # Example 2: Research Agenda

    Example 2 Input JSON:
    <example2_document_item>
    {
      "id": "a:evals_capability",
      "name": "Capability evals",
      "header_level": 2,
      "parent_id": "sec:evals",
      "content": null,
      "item_type": "agenda",
      "agenda_attributes": null,
      "parsing_issues": []
    }
    </example2_document_item>

    Example 2 Content:
    <example2_content>
    **Who edits (internal):** **Stephen** ✅
    **One-sentence summary:** Make tools that can actually check whether a model has a certain capability or propensity.
    **Theory of change:** Keep a close eye on what capabilities are acquired when, so that frontier labs and regulators are better informed on what security measures are already necessary (and hopefully they extrapolate). You can’t regulate without them.
    **See also:** [Deepmind’s frontier safety framework](https://deepmind.google/blog/strengthening-our-frontier-safety-framework/), [Aether](https://www.lesswrong.com/posts/B8Cmtf5gdHwxb8qtT/aether-july-2025-update). AGI metrics
    **Orthodox problems:** none; a barometer for risk.
    **Target case:** optimistic.
    **Broad approach:** Behavioral / Engineering.
    **Some names:** METR, AISI, Apollo Research, Marrius Hobbhahn, Meg Tong, Mary Phuong, Beth Barnes, Thomas Kwa, Joel Becker.

    **Estimated FTEs:** 100+
    **Critiques:** [Large Language Models Often Know When They Are Being Evaluated](https://arxiv.org/abs/2505.23836)**,** [AI Sandbagging: Language Models can Strategically Underperform on Evaluations](https://arxiv.org/abs/2406.07358),
    **Funded by:** basically everyone. Google, Microsoft, Open Philanthropy, LTFF, Governments etc
    **Outputs in 2025:**

    * [**Forecasting "Rare" Language Model Behaviors**](https://arxiv.org/abs/2502.16797), *Erik Jones, Meg Tong, Jesse Mu et al.*, 2025-02-24, arXiv
    * [**Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities**](https://arxiv.org/abs/2502.05209), *Zora Che, Stephen Casper, Robert Kirk et al.*, 2025-02-03, arXiv (accepted to TMLR)

    ### Game-theoretic evals
    * [**The Elicitation Game: Evaluating Capability Elicitation Techniques**](https://arxiv.org/abs/2502.02180), *Felix Hofstätter, Teun van der Weij, Jayden Teoh et al.*, 2025-02-04, arXiv
    * https://alignment.anthropic.com/2024/rogue-eval/index.html, 2024, Anthropic Alignment Science Blog
    *
    </example2_content>

    Example 2 Output JSON:
    ```json
    {
      "id": "a:evals_capability",
      "name": "Capability evals",
      "header_level": 2,
      "parent_id": "sec:evals",
      "content": null,
      "item_type": "agenda",
      "agenda_attributes": {
        "who_edits": "Stephen✅",
        "one_sentence_summary": "Make tools that can actually check whether a model has a certain capability or propensity. We default to low-n sampling of a vast latent space but aim to do better.",
        "theory_of_change": "Keep a close eye on what capabilities are acquired when, so that frontier labs and regulators are better informed on what security measures are already necessary (and hopefully they extrapolate). You can’t regulate without them.",
        "see_also": ["[Deepmind’s frontier safety framework](https://deepmind.google/blog/strengthening-our-frontier-safety-framework/)", "[Aether](https://www.lesswrong.com/posts/B8Cmtf5gdHwxb8qtT/aether-july-2025-update)", "a:agi_metrics"],
        "orthodox_problems": ["Other: none; a barometer for risk."],
        "target_case_id": "average_case",
        "target_case_text": "average",
        "broad_approach_id": null,
        "broad_approach_text": "behavioral / engineering",
        "some_names": ["METR", "AISI", "Apollo Research", "Marrius Hobbhahn", "Meg Tong", "Mary Phuong", "Beth Barnes", "Thomas Kwa", "Joel Becker"],
        "estimated_ftes": "100+",
        "funded_by": "basically everyone. Google, Microsoft, Open Philanthropy, LTFF, Governments etc",
        "outputs": [
          {
            "link_url": "https://arxiv.org/abs/2502.16797",
            "link_text": "Forecasting \"Rare\" Language Model Behaviors",
            "original_md": "* [**Forecasting \"Rare\" Language Model Behaviors**](https://arxiv.org/abs/2502.16797), *Erik Jones, Meg Tong, Jesse Mu et al.*, 2025-02-24, arXiv"
          },
          {
            "link_url": "https://arxiv.org/abs/2502.05209",
            "link_text": "Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities",
            "original_md": "* [**Model Tampering Attacks Enable More Rigorous Evaluations of LLM Capabilities**](https://arxiv.org/abs/2502.05209), *Zora Che, Stephen Casper, Robert Kirk et al.*, 2025-02-03, arXiv (accepted to TMLR)"
          }
          {
            "section_name": "Game-theoretic evals",
            "header_level": 3,
            "original_md": "### Game-theoretic evals"
          },
          {
            "link_url": "https://arxiv.org/abs/2502.02180",
            "link_text": "The Elicitation Game: Evaluating Capability Elicitation Techniques",
            "original_md": "* [**The Elicitation Game: Evaluating Capability Elicitation Techniques**](https://arxiv.org/abs/2502.02180), *Felix Hofstätter, Teun van der Weij, Jayden Teoh et al.*, 2025-02-04, arXiv"
          },
          {
            "link_url": "https://alignment.anthropic.com/2024/rogue-eval/index.html",
            "link_text": null,
            "original_md": "* https://alignment.anthropic.com/2024/rogue-eval/index.html, 2024, Anthropic Alignment Science Blog"
          }
        ]
      },
      "parsing_issues": [
        "Orthodox problems field says 'none; a barometer for risk.' - no matching problem found, kept as 'Other: none; a barometer for risk.'",
        "Target case field says 'optimistic.' - closest match is 'average_case'",
      ]
    }
    ```

    ## Notes on examples:

    - **Omit default values**: Fields with defaults (null, [], {}) can be omitted from output for brevity. The examples above show only non-default values.
    - Return valid JSON only. Do not use backslash escapes except for standard JSON escapes (\\n, \\t, \\", \\\\).
    - Preserve markdown formatting exactly as written in the source.

    # JSON Schema for Output

    Root DocumentItem (must match input structure exactly):
    - id: string (REQUIRED, must match input)
    - name: string (REQUIRED, must match input)
    - header_level: integer (REQUIRED, must match input)
    - parent_id: string | null (REQUIRED, must match input)
    - agenda_attributes: AgendaAttributes | null (REQUIRED, populate this)
    - content: string | null (REQUIRED, only the relevant content that is not represented in agenda_attributes, e.g. quotes, non-internal meta or epistemic remarks etc.; stand-alone markdown text; this should be empty for most agendas)
    - item_type: "section" | "agenda" (REQUIRED, must match input)
    - parsing_issues: string[] (defaults to [])

    AgendaAttributes (omit fields with default values, only populate the fields that are present):
    - who_edits: string | null
    - one_sentence_summary: string | null
    - theory_of_change: string | null
    - see_also: string[] (defaults to [])
    - orthodox_problems: string[] (defaults to [])
    - target_case: string | null
    - broad_approach: string | null
    - some_names: string[] (defaults to [])
    - estimated_ftes: string | null
    - critiques: string | null
    - funded_by: string | null
    - outputs: (Paper | OutputSectionHeader)[] (defaults to [])
    - other_attributes: object (defaults to {})

    Paper (also used for non-paper links and plaintext/non-link references):
    - link_url: string | null
    - link_text: string | null
    - original_md: string (REQUIRED)

    OutputSectionHeader:
    - section_name: string (REQUIRED)
    - header_level: integer (REQUIRED)
    - original_md: string (REQUIRED)
